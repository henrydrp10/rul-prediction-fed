{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import LSTM, Convolution1D, GlobalAveragePooling1D, Dense, Dropout, Masking, TimeDistributed\n",
    "import keras_tuner as kt\n",
    "\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.utils import median_survival_times\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.statistics import proportional_hazard_test\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import random\n",
    "import torchinfo\n",
    "\n",
    "# seed = 35\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# tf.random.set_seed(seed)\n",
    "\n",
    "# Check for TensorFlow GPU access\n",
    "print(f\"TensorFlow has access to the following devices:\\n{tf.config.list_physical_devices()}\")\n",
    "\n",
    "# See TensorFlow version\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_full_df = pd.read_csv('../data_analysis/scaled_train_data.csv', sep=' ')\n",
    "test_data_df = pd.read_csv('../data_analysis/scaled_test_data.csv', sep=' ')\n",
    "\n",
    "train_labels_full_df = pd.read_csv('../data_analysis/training_labels.csv', sep=' ')\n",
    "test_labels_df = pd.read_csv('../data_analysis/testing_labels.csv', sep=' ')\n",
    "test_labels_at_break_df = pd.read_csv('../TED/CMAPSSData/RUL_FD002.txt', sep=' ', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaplan Meier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding event_observed column: 0 for not-observed (test_data), 1 for observed (train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_train = train_data_full_df.copy()\n",
    "km_test = test_data_df.copy()\n",
    "km_train['Event Observed'] = 1\n",
    "km_test['Event Observed'] = 0\n",
    "\n",
    "km_total = pd.concat([km_train, km_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmf = KaplanMeierFitter()\n",
    "kmf.fit(durations = km_total['Cycle'], event_observed = km_total['Event Observed'])\n",
    "kmf.plot_survival_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_ = kmf.median_survival_time_\n",
    "median_confidence_interval_ = median_survival_times(kmf.confidence_interval_)\n",
    "print(median_)\n",
    "print(median_confidence_interval_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cox Proportional Hazard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cox_train = train_data_full_df.copy()\n",
    "cox_test = test_data_df.copy()\n",
    "cox_train['Event Observed'] = 1\n",
    "cox_test['Event Observed'] = 0\n",
    "\n",
    "cox_total = pd.concat([cox_train, cox_test])\n",
    "\n",
    "cox_total.drop(columns=['ID', 'OpSet1', 'OpSet2', 'OpSet3', 'SensorMeasure1', 'SensorMeasure5', 'SensorMeasure18', 'SensorMeasure19'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cox_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph = CoxPHFitter()\n",
    "cph.fit(cox_total, duration_col = 'Cycle', event_col = 'Event Observed')\n",
    "cph.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (10, 6))\n",
    "cph.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full_df = train_data_full_df.copy()\n",
    "test_df = test_data_df.copy()\n",
    "train_labels_full_df = train_labels_full_df.copy().clip(upper=125)\n",
    "test_labels_df = test_labels_df.copy()\n",
    "\n",
    "used_sensors = []\n",
    "used_sensors.append(\"ID\")\n",
    "used_sensors.append(\"Cycle\")\n",
    "for i in range(1, 22):\n",
    "    if i not in [1, 5, 6, 10, 16, 18, 19]:\n",
    "        used_sensors.append(\"SensorMeasure\" + str(i))\n",
    "\n",
    "train_full_df = train_full_df[used_sensors]\n",
    "test_df = test_df[used_sensors]\n",
    "\n",
    "# Processed data - Numpy\n",
    "train_full = train_full_df.values\n",
    "test = test_df.values\n",
    "train_labels_full = train_labels_full_df.values.squeeze()\n",
    "test_labels = test_labels_df.values.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_train_rul = train_full_df.copy()\n",
    "joined_train_rul['RUL'] = train_labels_full_df['RUL']\n",
    "test_at_break_df = test_df.groupby('ID').last().reset_index()\n",
    "test_at_break = test_at_break_df.values\n",
    "\n",
    "train_labels_at_break = joined_train_rul.groupby('ID').last().reset_index()['RUL'].values\n",
    "test_labels_at_break = test_labels_at_break_df.values[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_groupby_full_df = train_full_df.groupby('ID', sort=False)\n",
    "test_groupby_df = test_df.groupby('ID', sort=False)\n",
    "\n",
    "train_labels_full_df['ID'] = joined_train_rul['ID']\n",
    "train_labels_full_groupby_df = train_labels_full_df.groupby('ID', sort=False)\n",
    "\n",
    "val_indices = np.random.choice(len(train_groupby_full_df), size = int(0.2 * len(train_groupby_full_df)))\n",
    "\n",
    "val_arr = []\n",
    "train_set_arr = []\n",
    "val_labels_arr = []\n",
    "train_set_labels_arr = []\n",
    "\n",
    "for i in range(len(train_groupby_full_df)):\n",
    "    if i in val_indices:\n",
    "        val_arr.append(train_groupby_full_df.get_group(i+1))\n",
    "        val_labels_arr.append(train_labels_full_groupby_df.get_group(i+1)['RUL'])\n",
    "    else:\n",
    "        train_set_arr.append(train_groupby_full_df.get_group(i+1))\n",
    "        train_set_labels_arr.append(train_labels_full_groupby_df.get_group(i+1)['RUL'])\n",
    "\n",
    "val_set_df = val_arr[0]\n",
    "val_labels_df = val_labels_arr[0]\n",
    "for i in range(1, len(val_arr)):\n",
    "    val_set_df = pd.concat([val_set_df, val_arr[i]])\n",
    "    val_labels_df = pd.concat([val_labels_df, val_labels_arr[i]])\n",
    "\n",
    "train_set_df = train_set_arr[0]\n",
    "train_set_labels_df = train_set_labels_arr[0]\n",
    "for i in range(1, len(train_set_arr)):\n",
    "    train_set_df = pd.concat([train_set_df, train_set_arr[i]])\n",
    "    train_set_labels_df = pd.concat([train_set_labels_df, train_set_labels_arr[i]])\n",
    "\n",
    "train_set = train_set_df.values\n",
    "train_set_labels = train_set_labels_df.values\n",
    "val_set = val_set_df.values\n",
    "val_labels = val_labels_df.values\n",
    "val_labels = np.expand_dims(val_labels, axis = 1)\n",
    "train_set_labels = np.expand_dims(train_set_labels, axis = 1)\n",
    "train_labels_full = np.expand_dims(train_labels_full, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_full_df.shape, train_full.shape)\n",
    "print(train_labels_full_df.shape, train_labels_full.shape)\n",
    "print(train_set_df.shape, train_set.shape)\n",
    "print(train_set_labels_df.shape, train_set_labels.shape)\n",
    "print(val_set_df.shape, val_set.shape)\n",
    "print(val_labels_df.shape, val_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Windows extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows(data_df, labels_df, window_length, mode = 'train'):\n",
    "\n",
    "    if mode == 'train':\n",
    "\n",
    "        labels_df['ID'] = data_df['ID']\n",
    "\n",
    "        data_groupby = data_df.groupby('ID', sort=False)\n",
    "        labels_groupby = labels_df.groupby('ID', sort=False)\n",
    "\n",
    "        val_indices = np.random.choice(len(data_groupby), size = int(0.2 * len(data_groupby)))\n",
    "\n",
    "        tr_data_eng_arr = []\n",
    "        tr_labels_eng_arr = []\n",
    "\n",
    "        val_data_eng_arr = []\n",
    "        val_labels_eng_arr = []\n",
    "\n",
    "        for i in range(len(data_groupby)):\n",
    "            if i in val_indices:\n",
    "                val_data_eng_arr.append(data_groupby.get_group(i+1))\n",
    "            else:\n",
    "                tr_data_eng_arr.append(data_groupby.get_group(i+1))\n",
    "\n",
    "        for i in range(len(labels_groupby)):\n",
    "            if i in val_indices:\n",
    "                val_labels_eng_arr.append(labels_groupby.get_group(i+1))\n",
    "            else:\n",
    "                tr_labels_eng_arr.append(labels_groupby.get_group(i+1))\n",
    "\n",
    "        tr_data_windows = []\n",
    "        tr_label_windows = []\n",
    "        for index in range(len(tr_data_eng_arr)):\n",
    "            tr_data_arr = tr_data_eng_arr[index].to_numpy()\n",
    "            tr_labels_arr = tr_labels_eng_arr[index].to_numpy()\n",
    "            for t in range(tr_data_arr.shape[0] - window_length + 1):\n",
    "                tr_data_windows.append(tr_data_arr[t:t+window_length, :])\n",
    "                tr_label_windows.append(tr_labels_arr[t+window_length - 1, 0])\n",
    "\n",
    "        val_data_windows = []\n",
    "        val_label_windows = []\n",
    "        for index in range(len(val_data_eng_arr)):\n",
    "            val_data_arr = val_data_eng_arr[index].to_numpy()\n",
    "            val_labels_arr = val_labels_eng_arr[index].to_numpy()\n",
    "            for t in range(val_data_arr.shape[0] - window_length + 1):\n",
    "                val_data_windows.append(val_data_arr[t:t+window_length, :])\n",
    "                val_label_windows.append(val_labels_arr[t+window_length - 1, 0])\n",
    "\n",
    "        return np.array(tr_data_windows), np.array(tr_label_windows), np.array(val_data_windows), np.array(val_label_windows)\n",
    "\n",
    "    else:\n",
    "\n",
    "        labels_df['ID'] = data_df['ID']\n",
    "\n",
    "        data_groupby = data_df.groupby('ID', sort=False)\n",
    "        labels_groupby = labels_df.groupby('ID', sort=False)\n",
    "        data_eng_arr = []\n",
    "        labels_eng_arr = []\n",
    "\n",
    "        for i in range(len(data_groupby)):\n",
    "            data_eng_arr.append(data_groupby.get_group(i+1))\n",
    "\n",
    "        for i in range(len(labels_groupby)):\n",
    "            labels_eng_arr.append(labels_groupby.get_group(i+1))\n",
    "\n",
    "        data_windows = []\n",
    "        label_windows = []\n",
    "        for index in range(len(data_eng_arr)):\n",
    "            data_arr = data_eng_arr[index].to_numpy()\n",
    "            labels_arr = labels_eng_arr[index].to_numpy()\n",
    "            data_windows.append(data_arr[-window_length:, :])\n",
    "            label_windows.append(labels_arr[-1, 0])\n",
    "\n",
    "        return np.array(data_windows), np.array(label_windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "rf_param_grid = {\n",
    "    'bootstrap': [True, False], \n",
    "    'max_depth': [6, 7, 8, 9, 10], \n",
    "    'min_samples_leaf': [30, 35, 40, 45, 50],\n",
    "    'max_features': ['auto', 'log2', 'sqrt'], \n",
    "    'n_estimators': [100 * x for x in range(5, 11)],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=42)\n",
    "rand_search = RandomizedSearchCV(estimator = rf, param_distributions = rf_param_grid, cv = 3, n_jobs = 1, verbose = 3, return_train_score=True)\n",
    "rand_search.fit(train_full, train_labels_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_rf = rand_search.predict(test_at_break).round()\n",
    "print(rand_search.best_params_)\n",
    "rmse = np.sqrt(mean_squared_error(test_labels_at_break, predictions_rf))\n",
    "print(\"RMSE: \" + str(rmse))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor()\n",
    "gb.fit(train_full, train_labels_full)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_gb = gb.predict(test_at_break).round()\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(test_labels_at_break, predictions_gb))\n",
    "print(\"RMSE: \" + str(rmse))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmr = SVR(C=1.0, epsilon=0.2)\n",
    "svmr.fit(train_full, train_labels_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_svmr = svmr.predict(test_at_break).round()\n",
    "rmse = np.sqrt(mean_squared_error(test_labels_at_break, predictions_svmr))\n",
    "print(\"RMSE: \" + str(rmse))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron - Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = Sequential()\n",
    "mlp_model.add(Dense(32, activation = 'relu', input_dim = train_set.shape[1]))\n",
    "mlp_model.add(Dense(64, activation = 'relu'))\n",
    "mlp_model.add(Dense(128 , activation = 'relu'))\n",
    "mlp_model.add(Dropout(0.1))\n",
    "mlp_model.add(Dense(1, activation = 'relu'))\n",
    "\n",
    "\n",
    "mlp_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "mlp_model.summary()\n",
    "mlp_model.save_weights('mlp_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "mlp_model.load_weights('mlp_weights.h5') \n",
    "mlp_history = mlp_model.fit(train_set, train_set_labels, epochs=100, validation_data = (val_set, val_labels), batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT TRAIN AND VALIDATION LOSS\n",
    "def plot_loss(fit_history):\n",
    "    plt.figure(figsize=(13,5))\n",
    "    plt.plot(range(1, len(fit_history.history['loss'])+1), fit_history.history['loss'], label='train')\n",
    "    plt.plot(range(1, len(fit_history.history['val_loss'])+1), fit_history.history['val_loss'], label='validate')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(mlp_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING FUNCTION\n",
    "def evaluate(actual, pred, mode = 'test'):\n",
    "    mse = mean_squared_error(actual, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    variance = r2_score(actual, pred)\n",
    "    print(mode + ' set RMSE: ' + str(rmse) + ', R2: ' + str(variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING\n",
    "train_full_pred = mlp_model.predict(train_full)\n",
    "evaluate(train_labels_full, train_full_pred, 'train')\n",
    "\n",
    "test_at_break_pred = mlp_model.predict(test_at_break)\n",
    "evaluate(test_labels_at_break, test_at_break_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 20\n",
    "cnn_tr_data, cnn_tr_labels, cnn_val_data, cnn_val_labels = get_windows(train_full_df, train_labels_full_df, window_length, mode='train')\n",
    "cnn_test_data, cnn_test_labels = get_windows(test_df, test_labels_df, 20, mode = 'test')\n",
    "\n",
    "cnn_tr_labels = np.expand_dims(cnn_tr_labels, axis=1)\n",
    "cnn_val_labels = np.expand_dims(cnn_val_labels, axis=1)\n",
    "cnn_test_labels = np.expand_dims(cnn_test_labels, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential()\n",
    "cnn_model.add(Convolution1D(256, 3, input_shape = (window_length, cnn_tr_data.shape[2])))\n",
    "cnn_model.add(Convolution1D(128, 3, activation = 'relu'))\n",
    "cnn_model.add(Convolution1D(64, 3, activation = 'relu'))\n",
    "cnn_model.add(GlobalAveragePooling1D(data_format = 'channels_last', keepdims = False))\n",
    "cnn_model.add(Dense(1, activation = 'relu'))\n",
    "\n",
    "cnn_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "cnn_model.save_weights('simple_lstm_weights.h5')\n",
    "\n",
    "cnn_model.compile(loss='mean_squared_error', optimizer='adam')  \n",
    "cnn_model.load_weights('simple_lstm_weights.h5')  \n",
    "\n",
    "history = cnn_model.fit(cnn_tr_data, cnn_tr_labels,\n",
    "                        validation_data=(cnn_val_data, cnn_val_labels),\n",
    "                        epochs=50,\n",
    "                        batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING FUNCTION\n",
    "def evaluate(actual, pred, mode = 'test'):\n",
    "    mse = mean_squared_error(actual, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    variance = r2_score(actual, pred)\n",
    "    print(mode + ' set RMSE: ' + str(rmse) + ', R2: ' + str(variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING\n",
    "train_cnn_pred = cnn_model.predict(cnn_tr_data)\n",
    "evaluate(cnn_tr_labels, train_cnn_pred, 'train')\n",
    "\n",
    "test_cnn_pred = cnn_model.predict(cnn_test_data)\n",
    "evaluate(cnn_test_labels, test_cnn_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(32, activation='tanh', input_shape=(window_length, cnn_tr_data.shape[2])))\n",
    "lstm_model.add(Dense(1))\n",
    "\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "lstm_model.save_weights('simple_lstm_weights.h5')\n",
    "\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer='adam')  \n",
    "lstm_model.load_weights('simple_lstm_weights.h5')  \n",
    "\n",
    "history = lstm_model.fit(cnn_tr_data, cnn_tr_labels,\n",
    "                        validation_data=(cnn_val_data, cnn_val_labels),\n",
    "                        epochs=50,\n",
    "                        batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT LOSS HISTORY\n",
    "def plot_loss(fit_history):\n",
    "    plt.figure(figsize=(13,5))\n",
    "    plt.plot(range(1, len(fit_history.history['loss'])+1), fit_history.history['loss'], label='train')\n",
    "    plt.plot(range(1, len(fit_history.history['val_loss'])+1), fit_history.history['val_loss'], label='validate')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING FUNCTION\n",
    "def evaluate(actual, pred, mode = 'test'):\n",
    "    mse = mean_squared_error(actual, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    variance = r2_score(actual, pred)\n",
    "    print(mode + ' set RMSE: ' + str(rmse) + ', R2: ' + str(variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING\n",
    "train_cnn_pred = lstm_model.predict(cnn_tr_data)\n",
    "evaluate(cnn_tr_labels, train_cnn_pred, 'train')\n",
    "\n",
    "test_cnn_pred = lstm_model.predict(cnn_test_data)\n",
    "evaluate(cnn_test_labels, test_cnn_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf-m1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7db919a617d352c2dafc671a388d65b97a697f0535deb448e14c82fa78835651"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
