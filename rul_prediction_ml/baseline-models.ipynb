{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow has access to the following devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "TensorFlow version: 2.9.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import LSTM, Convolution1D, GlobalAveragePooling1D, Dense, Dropout\n",
    "import keras_tuner as kt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Check for TensorFlow GPU access\n",
    "print(f\"TensorFlow has access to the following devices:\\n{tf.config.list_physical_devices()}\")\n",
    "\n",
    "# See TensorFlow version\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df = pd.read_csv('../data_analysis/fd001/fd001-scaled_train.csv', sep=' ')\n",
    "test_data_df = pd.read_csv('../data_analysis/fd001/fd001-scaled_test.csv', sep=' ')\n",
    "\n",
    "train_labels_df = pd.read_csv('../data_analysis/fd001/fd001-training_labels.csv', sep=' ')\n",
    "test_labels_df = pd.read_csv('../data_analysis/fd001/fd001-testing_labels.csv', sep=' ')\n",
    "test_labels_at_break_df = pd.DataFrame(pd.read_csv('../TED/CMAPSSData/RUL_FD001.txt', sep=' ', header=None)[0])\n",
    "test_labels_at_break_df.columns = ['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_at_break_df = test_data_df.groupby(['ID'], sort=False).last().reset_index()\n",
    "train_labels_df = train_labels_df.clip(upper = 125)\n",
    "test_labels_df = test_labels_df.clip(upper = 125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Windows extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows(data_df, labels_df, window_length, mode = 'train'):\n",
    "\n",
    "    if mode == 'train':\n",
    "\n",
    "        labels_df['ID'] = data_df['ID']\n",
    "\n",
    "        data_groupby = data_df.groupby('ID', sort=False)\n",
    "        labels_groupby = labels_df.groupby('ID', sort=False)\n",
    "\n",
    "        val_indices = np.random.choice(len(data_groupby), size = int(0.2 * len(data_groupby)))\n",
    "\n",
    "        tr_data_eng_arr = []\n",
    "        tr_labels_eng_arr = []\n",
    "\n",
    "        val_data_eng_arr = []\n",
    "        val_labels_eng_arr = []\n",
    "\n",
    "        for i in range(len(data_groupby)):\n",
    "            if i in val_indices:\n",
    "                val_data_eng_arr.append(data_groupby.get_group(i+1))\n",
    "            else:\n",
    "                tr_data_eng_arr.append(data_groupby.get_group(i+1))\n",
    "\n",
    "        for i in range(len(labels_groupby)):\n",
    "            if i in val_indices:\n",
    "                val_labels_eng_arr.append(labels_groupby.get_group(i+1))\n",
    "            else:\n",
    "                tr_labels_eng_arr.append(labels_groupby.get_group(i+1))\n",
    "\n",
    "        tr_data_windows = []\n",
    "        tr_label_windows = []\n",
    "        for index in range(len(tr_data_eng_arr)):\n",
    "            tr_data_arr = tr_data_eng_arr[index].to_numpy()\n",
    "            tr_labels_arr = tr_labels_eng_arr[index].to_numpy()\n",
    "            for t in range(tr_data_arr.shape[0] - window_length + 1):\n",
    "                tr_data_windows.append(tr_data_arr[t:t+window_length, :])\n",
    "                tr_label_windows.append(tr_labels_arr[t+window_length - 1])\n",
    "\n",
    "        val_data_windows = []\n",
    "        val_label_windows = []\n",
    "        for index in range(len(val_data_eng_arr)):\n",
    "            val_data_arr = val_data_eng_arr[index].to_numpy()\n",
    "            val_labels_arr = val_labels_eng_arr[index].to_numpy()\n",
    "            for t in range(val_data_arr.shape[0] - window_length + 1):\n",
    "                val_data_windows.append(val_data_arr[t:t+window_length, :])\n",
    "                val_label_windows.append(val_labels_arr[t+window_length - 1])\n",
    "\n",
    "        return np.array(tr_data_windows), np.array(tr_label_windows), np.array(val_data_windows), np.array(val_label_windows)\n",
    "\n",
    "    else:\n",
    "\n",
    "        labels_df['ID'] = data_df['ID']\n",
    "\n",
    "        data_groupby = data_df.groupby('ID', sort=False)\n",
    "        labels_groupby = labels_df.groupby('ID', sort=False)\n",
    "        data_eng_arr = []\n",
    "        labels_eng_arr = []\n",
    "\n",
    "        for i in range(len(data_groupby)):\n",
    "            data_eng_arr.append(data_groupby.get_group(i+1))\n",
    "\n",
    "        for i in range(len(labels_groupby)):\n",
    "            labels_eng_arr.append(labels_groupby.get_group(i+1))\n",
    "\n",
    "        data_windows = []\n",
    "        label_windows = []\n",
    "        for index in range(len(data_eng_arr)):\n",
    "            data_arr = data_eng_arr[index].to_numpy()\n",
    "            labels_arr = labels_eng_arr[index].to_numpy()\n",
    "            data_windows.append(data_arr[-window_length:, :])\n",
    "            label_windows.append(labels_arr[-1, 0])\n",
    "\n",
    "        return np.array(data_windows), np.array(label_windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide train set between train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_df['ID'] = train_data_df['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_groupby_df = train_data_df.groupby(['ID'], sort = False)\n",
    "train_labels_groupby_df = train_labels_df.groupby(['ID'], sort = False)\n",
    "val_indices = np.random.choice(len(train_groupby_df), size = int(0.2 * len(train_groupby_df)))\n",
    "\n",
    "train_labels_df = train_labels_df['RUL']\n",
    "\n",
    "val_arr = []\n",
    "train_set_arr = []\n",
    "val_labels_arr = []\n",
    "train_set_labels_arr = []\n",
    "\n",
    "for i in range(len(train_groupby_df)):\n",
    "    if i in val_indices:\n",
    "        val_arr.append(train_groupby_df.get_group(i+1))\n",
    "        val_labels_arr.append(train_labels_groupby_df.get_group(i+1)['RUL'])\n",
    "    else:\n",
    "        train_set_arr.append(train_groupby_df.get_group(i+1))\n",
    "        train_set_labels_arr.append(train_labels_groupby_df.get_group(i+1)['RUL'])\n",
    "\n",
    "val_set_df = val_arr[0]\n",
    "val_labels_df = val_labels_arr[0]\n",
    "for i in range(1, len(val_arr)):\n",
    "    val_set_df = pd.concat([val_set_df, val_arr[i]])\n",
    "    val_labels_df = pd.concat([val_labels_df, val_labels_arr[i]])\n",
    "\n",
    "train_set_df = train_set_arr[0]\n",
    "train_set_labels_df = train_set_labels_arr[0]\n",
    "for i in range(1, len(train_set_arr)):\n",
    "    train_set_df = pd.concat([train_set_df, train_set_arr[i]])\n",
    "    train_set_labels_df = pd.concat([train_set_labels_df, train_set_labels_arr[i]])\n",
    "\n",
    "train_set = train_set_df.values\n",
    "train_set_labels = train_set_labels_df.values\n",
    "val_set = val_set_df.values\n",
    "val_labels = val_labels_df.values\n",
    "val_labels = np.expand_dims(val_labels, axis = 1)\n",
    "train_set_labels = np.expand_dims(train_set_labels, axis = 1)\n",
    "train_labels = np.expand_dims(train_labels_df.values, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SensorMeasure2', 'SensorMeasure3', 'SensorMeasure4', 'SensorMeasure7',\n",
       "       'SensorMeasure8', 'SensorMeasure9', 'SensorMeasure11',\n",
       "       'SensorMeasure12', 'SensorMeasure13', 'SensorMeasure14',\n",
       "       'SensorMeasure15', 'SensorMeasure17', 'SensorMeasure20',\n",
       "       'SensorMeasure21'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms_used = train_data_df.columns[2:]\n",
    "ms_used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_param_grid = {\n",
    "#     'bootstrap': [True, False], \n",
    "#     'max_depth': [6, 7, 8, 9, 10], \n",
    "#     'min_samples_leaf': [30, 35, 40, 45, 50],\n",
    "#     'max_features': ['log2', 'sqrt'], \n",
    "#     'n_estimators': [100 * x for x in range(5, 11)],\n",
    "#     }\n",
    "\n",
    "# rf = RandomForestRegressor(random_state=42)\n",
    "# rand_search_rf = RandomizedSearchCV(estimator = rf, param_distributions = rf_param_grid, cv = 3, n_jobs = 1, verbose = 3, return_train_score=True)\n",
    "# rand_search_rf.fit(train_data_df[ms_used].values, train_labels_df.values.squeeze())\n",
    "# rf_results = pd.DataFrame(rand_search_rf.cv_results_)\n",
    "\n",
    "# predictions_rf = rand_search_rf.predict(test_at_break_df[ms_used].values).round()\n",
    "# print(rand_search_rf.best_params_)\n",
    "# rmse = np.sqrt(mean_squared_error(test_labels_at_break_df.values, predictions_rf))\n",
    "# print(\"RMSE: \" + str(rmse)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df[ms_used]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = RandomForestRegressor(n_estimators=100, max_features=\"sqrt\", random_state=42, max_depth=8, min_samples_leaf=50)\n",
    "best_rf.fit(train_data_df[ms_used].values, train_labels_df.values.squeeze())\n",
    "predictions_rf = best_rf.predict(test_at_break_df[ms_used].values).round()\n",
    "rmse = np.sqrt(mean_squared_error(test_labels_at_break_df.values, predictions_rf))\n",
    "print(\"RMSE: \" + str(rmse)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gb_params = {\n",
    "#     'learning_rate': [0.001, 0.05, 0.1, 0.2, 0.3],\n",
    "#     'n_estimators': [100 * x for x in range(5, 11)],\n",
    "#     'subsample': [0.75, 0.85, 0.95, 1],\n",
    "#     'min_samples_leaf': [30, 35, 40, 45, 50],\n",
    "# }\n",
    "\n",
    "# gb = GradientBoostingRegressor()\n",
    "# rand_search_gb = RandomizedSearchCV(estimator = gb, param_distributions = gb_params, cv = 3, n_jobs = 1, verbose = 3, return_train_score=True)\n",
    "# rand_search_gb.fit(train_data_df.values[:,1:], train_labels_df['RUL'].values.squeeze())\n",
    "\n",
    "# predictions_gb = rand_search_gb.predict(test_at_break_df.values[:,1:]).round()\n",
    "# print(rand_search_gb.best_params_)\n",
    "# rmse = np.sqrt(mean_squared_error(test_labels_at_break_df.values, predictions_gb))\n",
    "# print(\"RMSE: \" + str(rmse)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gb = RandomForestRegressor(random_state=42, n_estimators = 900, min_samples_leaf = 40, max_features = 'sqrt', max_depth = 10)\n",
    "best_gb.fit(train_data_df[ms_used].values, train_labels_df.values.squeeze())\n",
    "predictions_gb = best_gb.predict(test_at_break_df[ms_used].values).round()\n",
    "rmse = np.sqrt(mean_squared_error(test_labels_at_break_df.values, predictions_gb))\n",
    "print(\"RMSE: \" + str(rmse)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svmr_params = {\n",
    "#     'kernel': ['rbf', 'linear', 'poly'],\n",
    "#     'C': [1, 2, 5, 10],\n",
    "#     'epsilon': [0.1 * i for i in range(1, 6)]\n",
    "# }\n",
    "\n",
    "# svmr = SVR()\n",
    "# rand_search_svmr = RandomizedSearchCV(estimator = svmr, param_distributions = svmr_params, cv = 3, n_jobs = 1, verbose = 3, return_train_score=True)\n",
    "# rand_search_svmr.fit(train_data_df[ms_used].values, train_labels_df.values.squeeze())\n",
    "\n",
    "# predictions_svmr = rand_search_svmr.predict(test_at_break_df[ms_used].values).round()\n",
    "# print(rand_search_svmr.best_params_)\n",
    "# rmse = np.sqrt(mean_squared_error(test_labels_at_break_df.values, predictions_svmr))\n",
    "# print(\"RMSE: \" + str(rmse)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 43.80096110302132\n"
     ]
    }
   ],
   "source": [
    "best_svmr = SVR(C = 1, epsilon = 0.0)\n",
    "best_svmr.fit(train_data_df[ms_used].values, train_labels_df.values.squeeze())\n",
    "predictions_svmr = best_svmr.predict(test_at_break_df[ms_used].values).round()\n",
    "rmse = np.sqrt(mean_squared_error(test_labels_at_break_df.values, predictions_svmr))\n",
    "print(\"RMSE: \" + str(rmse)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron - Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 20\n",
    "mlp_tr_data, mlp_tr_labels, mlp_val_data, mlp_val_labels = get_windows(train_data_df, train_labels_df, window_length, mode='train')\n",
    "mlp_test_data, mlp_test_labels = get_windows(test_data_df, test_labels_df, 20, mode = 'test')\n",
    "\n",
    "mlp_tr_data = mlp_tr_data.reshape(mlp_tr_data.shape[0], -1)\n",
    "mlp_val_data = mlp_val_data.reshape(mlp_val_data.shape[0], -1)\n",
    "mlp_test_data = mlp_test_data.reshape(mlp_test_data.shape[0], -1)\n",
    "\n",
    "mlp_tr_labels = np.expand_dims(mlp_tr_labels, axis=1)\n",
    "mlp_val_labels = np.expand_dims(mlp_val_labels, axis=1)\n",
    "mlp_test_labels = np.expand_dims(mlp_test_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project baseline_models/mlp/oracle.json\n",
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "INFO:tensorflow:Reloading Tuner from baseline_models/mlp/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-29 00:27:37.054452: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-29 00:27:37.054582: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "def mlp_model_builder(hp):\n",
    "\n",
    "    hp_units1 = hp.Int('units1', min_value=32, max_value=128, step=32)\n",
    "    hp_units2 = hp.Int('units2', min_value=32, max_value=128, step=32)\n",
    "    hp_units3 = hp.Int('units3', min_value=32, max_value=128, step=32)\n",
    "\n",
    "    hp_dropout = hp.Choice('dropout_rate', values=[0.1, 0.2, 0.3, 0.4])\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[0.001, 0.005, 0.01, 0.05])\n",
    "\n",
    "    mlp_model = Sequential()\n",
    "    mlp_model.add(Dense(units = hp_units1, activation = 'relu', input_dim = train_set_df[ms_used].values.shape[1]))\n",
    "    mlp_model.add(Dropout(hp_dropout))\n",
    "    mlp_model.add(Dense(units = hp_units2, activation = 'relu'))\n",
    "    mlp_model.add(Dropout(hp_dropout))\n",
    "    mlp_model.add(Dense(units = hp_units3 , activation = 'relu'))\n",
    "    mlp_model.add(Dropout(hp_dropout))\n",
    "    mlp_model.add(Dense(1, activation = 'relu'))\n",
    "\n",
    "    mlp_model.compile(optimizer=keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                loss=keras.losses.MeanSquaredError())\n",
    "\n",
    "    return mlp_model\n",
    "\n",
    "mlp_tuner = kt.BayesianOptimization(mlp_model_builder,\n",
    "                                    objective='val_loss',\n",
    "                                    max_trials = 9,\n",
    "                                    directory='baseline_models',\n",
    "                                    project_name='mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_tuner.search(mlp_tr_data, mlp_tr_labels, epochs=100, validation_data = (mlp_val_data, mlp_val_labels), batch_size = 256)\n",
    "best_mlp_hps = mlp_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "best_mlp_model = mlp_tuner.hypermodel.build(best_mlp_hps)\n",
    "mlp_history = best_mlp_model.fit(mlp_tr_data, mlp_tr_labels, epochs=100, validation_data = (mlp_val_data, mlp_val_labels), batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #5\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "128               |128               |units1\n",
      "32                |32                |units2\n",
      "128               |32                |units3\n",
      "0.1               |0.1               |dropout_rate\n",
      "0.001             |0.001             |learning_rate\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-29 00:27:52.768364: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/henry/.virtualenvs/tf-m1/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/henry/.virtualenvs/tf-m1/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/henry/.virtualenvs/tf-m1/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/henry/.virtualenvs/tf-m1/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/henry/.virtualenvs/tf-m1/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/henry/.virtualenvs/tf-m1/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 360), found shape=(None, 16)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/henry/Documents/Imperial/Masters' Project/rul-prediction-fed/rul_prediction_ml/baseline-models.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/henry/Documents/Imperial/Masters%27%20Project/rul-prediction-fed/rul_prediction_ml/baseline-models.ipynb#ch0000060?line=0'>1</a>\u001b[0m mlp_tuner\u001b[39m.\u001b[39;49msearch(train_set_df[ms_used]\u001b[39m.\u001b[39;49mvalues, train_set_labels\u001b[39m.\u001b[39;49msqueeze(), epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, validation_data \u001b[39m=\u001b[39;49m (val_set_df[ms_used]\u001b[39m.\u001b[39;49mvalues, val_labels\u001b[39m.\u001b[39;49msqueeze()), batch_size \u001b[39m=\u001b[39;49m \u001b[39m256\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/henry/Documents/Imperial/Masters%27%20Project/rul-prediction-fed/rul_prediction_ml/baseline-models.ipynb#ch0000060?line=1'>2</a>\u001b[0m best_mlp_hps \u001b[39m=\u001b[39m mlp_tuner\u001b[39m.\u001b[39mget_best_hyperparameters(num_trials\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/henry/Documents/Imperial/Masters%27%20Project/rul-prediction-fed/rul_prediction_ml/baseline-models.ipynb#ch0000060?line=3'>4</a>\u001b[0m best_mlp_model \u001b[39m=\u001b[39m mlp_tuner\u001b[39m.\u001b[39mhypermodel\u001b[39m.\u001b[39mbuild(best_mlp_hps)\n",
      "File \u001b[0;32m~/.virtualenvs/tf-m1/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py:183\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 183\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    184\u001b[0m \u001b[39m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39mif\u001b[39;00m results \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.virtualenvs/tf-m1/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:295\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    294\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[0;32m--> 295\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[1;32m    297\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[1;32m    298\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/.virtualenvs/tf-m1/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:222\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[1;32m    221\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 222\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mfit(hp, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    223\u001b[0m tuner_utils\u001b[39m.\u001b[39mvalidate_trial_results(\n\u001b[1;32m    224\u001b[0m     results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective, \u001b[39m\"\u001b[39m\u001b[39mHyperModel.fit()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m )\n\u001b[1;32m    226\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/.virtualenvs/tf-m1/lib/python3.9/site-packages/keras_tuner/engine/hypermodel.py:140\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    117\u001b[0m     \u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \n\u001b[1;32m    119\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.virtualenvs/tf-m1/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/4z/dx20wtl948x13fj468s2l3280000gn/T/__autograph_generated_filevadw84fh.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/henry/.virtualenvs/tf-m1/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/henry/.virtualenvs/tf-m1/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/henry/.virtualenvs/tf-m1/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/henry/.virtualenvs/tf-m1/lib/python3.9/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/henry/.virtualenvs/tf-m1/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/henry/.virtualenvs/tf-m1/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 360), found shape=(None, 16)\n"
     ]
    }
   ],
   "source": [
    "mlp_tuner.search(train_set_df[ms_used].values, train_set_labels.squeeze(), epochs=100, validation_data = (val_set_df[ms_used].values, val_labels.squeeze()), batch_size = 256)\n",
    "best_mlp_hps = mlp_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "best_mlp_model = mlp_tuner.hypermodel.build(best_mlp_hps)\n",
    "mlp_history = best_mlp_model.fit(train_set_df[ms_used].values, train_set_labels.squeeze(), epochs=100, validation_data = (val_set_df[ms_used].values, val_labels.squeeze()), batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT TRAIN AND VALIDATION LOSS\n",
    "def plot_loss(fit_history):\n",
    "    plt.figure(figsize=(13,5))\n",
    "    plt.plot(range(1, len(fit_history.history['loss'])+1), fit_history.history['loss'], label='train')\n",
    "    plt.plot(range(1, len(fit_history.history['val_loss'])+1), fit_history.history['val_loss'], label='validate')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(mlp_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING FUNCTION\n",
    "def testing(actual, pred, mode = 'Test'):\n",
    "    mse = mean_squared_error(actual, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    variance = r2_score(actual, pred)\n",
    "    print(mode + ' set RMSE: ' + str(rmse) + ', R2: ' + str(variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full_pred = best_mlp_model.predict(mlp_tr_data)\n",
    "testing(mlp_tr_labels, train_full_pred, 'Train')\n",
    "\n",
    "test_at_break_pred = best_mlp_model.predict(mlp_test_data)\n",
    "testing(mlp_test_labels, test_at_break_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full_pred = best_mlp_model.predict(train_data_df[ms_used].values)\n",
    "testing(train_labels_df.values.squeeze(), train_full_pred, 'Train')\n",
    "\n",
    "test_at_break_pred = best_mlp_model.predict(test_at_break_df[ms_used].values)\n",
    "testing(test_labels_at_break_df.values.squeeze(), test_at_break_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 20\n",
    "cnn_tr_data, cnn_tr_labels, cnn_val_data, cnn_val_labels = get_windows(train_data_df, train_labels_df, window_length, mode='train')\n",
    "cnn_test_data, cnn_test_labels = get_windows(test_data_df, test_labels_df, 20, mode = 'test')\n",
    "\n",
    "cnn_tr_labels = np.expand_dims(cnn_tr_labels, axis=1)\n",
    "cnn_val_labels = np.expand_dims(cnn_val_labels, axis=1)\n",
    "cnn_test_labels = np.expand_dims(cnn_test_labels, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential()\n",
    "cnn_model.add(Convolution1D(256, 3, input_shape = (window_length, cnn_tr_data.shape[2])))\n",
    "cnn_model.add(Convolution1D(128, 3, activation = 'relu'))\n",
    "cnn_model.add(Convolution1D(64, 3, activation = 'relu'))\n",
    "cnn_model.add(GlobalAveragePooling1D(data_format = 'channels_last', keepdims = False))\n",
    "cnn_model.add(Dense(1, activation = 'relu'))\n",
    "\n",
    "cnn_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "cnn_model.save_weights('simple_lstm_weights.h5')\n",
    "\n",
    "cnn_model.compile(loss='mean_squared_error', optimizer='adam')  \n",
    "cnn_model.load_weights('simple_lstm_weights.h5')  \n",
    "\n",
    "history = cnn_model.fit(cnn_tr_data, cnn_tr_labels,\n",
    "                        validation_data=(cnn_val_data, cnn_val_labels),\n",
    "                        epochs=50,\n",
    "                        batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING FUNCTION\n",
    "def evaluate(actual, pred, mode = 'test'):\n",
    "    mse = mean_squared_error(actual, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    variance = r2_score(actual, pred)\n",
    "    print(mode + ' set RMSE: ' + str(rmse) + ', R2: ' + str(variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING\n",
    "train_cnn_pred = cnn_model.predict(cnn_tr_data)\n",
    "evaluate(cnn_tr_labels, train_cnn_pred, 'train')\n",
    "\n",
    "test_cnn_pred = cnn_model.predict(cnn_test_data)\n",
    "evaluate(cnn_test_labels, test_cnn_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(32, activation='tanh', input_shape=(window_length, cnn_tr_data.shape[2])))\n",
    "lstm_model.add(Dense(1))\n",
    "\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "lstm_model.save_weights('simple_lstm_weights.h5')\n",
    "\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer='adam')  \n",
    "lstm_model.load_weights('simple_lstm_weights.h5')  \n",
    "\n",
    "history = lstm_model.fit(cnn_tr_data, cnn_tr_labels,\n",
    "                        validation_data=(cnn_val_data, cnn_val_labels),\n",
    "                        epochs=50,\n",
    "                        batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT LOSS HISTORY\n",
    "def plot_loss(fit_history):\n",
    "    plt.figure(figsize=(13,5))\n",
    "    plt.plot(range(1, len(fit_history.history['loss'])+1), fit_history.history['loss'], label='train')\n",
    "    plt.plot(range(1, len(fit_history.history['val_loss'])+1), fit_history.history['val_loss'], label='validate')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING FUNCTION\n",
    "def evaluate(actual, pred, mode = 'test'):\n",
    "    mse = mean_squared_error(actual, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    variance = r2_score(actual, pred)\n",
    "    print(mode + ' set RMSE: ' + str(rmse) + ', R2: ' + str(variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING\n",
    "train_cnn_pred = lstm_model.predict(cnn_tr_data)\n",
    "evaluate(cnn_tr_labels, train_cnn_pred, 'train')\n",
    "\n",
    "test_cnn_pred = lstm_model.predict(cnn_test_data)\n",
    "evaluate(cnn_test_labels, test_cnn_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf-m1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7db919a617d352c2dafc671a388d65b97a697f0535deb448e14c82fa78835651"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
